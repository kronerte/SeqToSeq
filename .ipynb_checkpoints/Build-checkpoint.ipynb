{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading app.ML\n",
      "Reloading app.ML.model\n",
      "Reloading app.ML.in_out\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'app' from 'app/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allow recursive reloading\n",
    "import builtins\n",
    "from IPython.lib import deepreload\n",
    "builtins.reload = deepreload.reload\n",
    "import app\n",
    "builtins.reload(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import useful librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the data from http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anglais</th>\n",
       "      <th>français</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  anglais  français\n",
       "0     Go.      Va !\n",
       "1     Hi.   Salut !\n",
       "2    Run!   Cours !\n",
       "3    Run!  Courez !\n",
       "4    Who?     Qui ?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donnees = pd.read_csv('Data/fra-eng/fra.txt',sep='\\t',header=None, names=['anglais','français'])[:10000]\n",
    "donnees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anglais</th>\n",
       "      <th>français</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Don't overdo it.</td>\n",
       "      <td>N'en fais pas trop.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Don't play dumb!</td>\n",
       "      <td>Ne fais pas l'imbécile.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Don't remind me.</td>\n",
       "      <td>Ne me le rappelle pas !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Don't remind me.</td>\n",
       "      <td>Ne me le rappelez pas !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Don't resist us.</td>\n",
       "      <td>Ne nous résiste pas !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               anglais                 français\n",
       "9995  Don't overdo it.      N'en fais pas trop.\n",
       "9996  Don't play dumb!  Ne fais pas l'imbécile.\n",
       "9997  Don't remind me.  Ne me le rappelle pas !\n",
       "9998  Don't remind me.  Ne me le rappelez pas !\n",
       "9999  Don't resist us.    Ne nous résiste pas !"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donnees.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees['français'] = donnees[\"français\"].apply(lambda x : '\\t' + x + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to transform the sequences into numpy arrays<br>\n",
    "We will use character-level one-hot encoding.<br>\n",
    "We will have 3 vectors types :\n",
    "     - Encoder input\n",
    "     - decoder input\n",
    "     - decoder labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocable():\n",
    "    def __init__(self):\n",
    "        self._char_to_int = dict()\n",
    "        self._int_to_char = []\n",
    "        self.voc_size = 0\n",
    "        self.max_sentence_size = 0\n",
    "    \n",
    "    def train(self, L):\n",
    "        all_char = set()\n",
    "        m = 0\n",
    "        for s in L:\n",
    "            all_char.update(list(s))\n",
    "            if len(s)>m:\n",
    "                m = len(s)\n",
    "       \n",
    "        self.max_sentence_size = m\n",
    "        chars = sorted(list(all_char))\n",
    "        self.voc_size = len(chars)\n",
    "        self._int_to_char = chars\n",
    "        self._char_to_int = dict([(chars[i],i) for i in range(len(chars))])\n",
    "            \n",
    "    def getChar(self, i):\n",
    "        return self._int_to_char[i]\n",
    "    \n",
    "    def getInt(self, c):\n",
    "        return self._char_to_int[c]\n",
    "    \n",
    "    def vectoriseSetence(self, sentence):\n",
    "        res = np.zeros((self.max_sentence_size, self.voc_size))\n",
    "        for i in range(len(sentence)):\n",
    "            res[i][self.getInt(sentence[i])] = 1\n",
    "        return res\n",
    "    \n",
    "    def decodeVec(self, vec):\n",
    "        res = \"\"\n",
    "        for i in range(vec.shape[0]):\n",
    "            res += self.getChar(np.argmax(vec[i]))\n",
    "        return res\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_voc = Vocable()\n",
    "eng_voc.train(donnees['anglais'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = eng_voc.vectoriseSetence(\"Hey\")\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey             '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_voc.decodeVec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_voc = Vocable()\n",
    "fra_voc.train(donnees['français'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees['input_encoder'] = donnees[\"anglais\"].apply(eng_voc.vectoriseSetence)\n",
    "donnees['input_decoder'] = donnees[\"français\"].apply(fra_voc.vectoriseSetence)\n",
    "donnees['output_decoder'] = donnees['input_decoder'].apply(lambda vec: np.vstack((vec[1:],0*vec[0].reshape((1,-1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder = np.r_[list(donnees['input_encoder'])]\n",
    "input_decoder = np.r_[list(donnees['input_decoder'])]\n",
    "output_decoder =np.r_[list(donnees['output_decoder'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('Data/fra-eng/processed_data',\n",
    "                    input_encoder=input_encoder,\n",
    "                    input_decoder=input_decoder,\n",
    "                    output_decoder=output_decoder\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"app/ML/dico_eng.pickle\",\"wb\") as f:\n",
    "    pickle.dump(eng_voc, f)\n",
    "with open(\"app/ML/dico_fra.pickle\",\"wb\") as f:\n",
    "    pickle.dump(fra_voc, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"app/ML/dico_eng.pickle\",\"rb\") as f:\n",
    "    eng_voc = pickle.load(f)\n",
    "with open(\"app/ML/dico_fra.pickle\",\"rb\") as f:\n",
    "    fra_voc = pickle.load(f)\n",
    "\n",
    "loaded = np.load('Data/fra-eng/processed_data.npz')\n",
    "\n",
    "input_encoder = loaded['input_encoder']\n",
    "input_decoder = loaded['input_decoder']\n",
    "output_decoder = loaded['output_decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Va !\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_voc.decodeVec(output_decoder[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
